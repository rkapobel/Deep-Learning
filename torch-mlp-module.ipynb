{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 100\n",
    "N = 8\n",
    "H = N + 1\n",
    "M = 1\n",
    "\n",
    "x = torch.randn(P, N).sign()\n",
    "z = torch.prod(x, dim = 1).view(P, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential( # Seq es feedforward.\n",
    "torch.nn.Linear(N, H), # Linear son los pesos. \n",
    "torch.nn.Tanh(), # Tanh es la activacion.\n",
    "torch.nn.Linear(H, M), # Linear incluye los bias \n",
    "torch.nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=9, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=9, out_features=1, bias=True)\n",
      "  (3): Tanh()\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.1242, -0.0587,  0.1343,  0.2541,  0.3019,  0.1887, -0.1648,  0.1282],\n",
      "        [ 0.0688, -0.3116,  0.3133,  0.3031, -0.0487, -0.0810,  0.1016, -0.0170],\n",
      "        [ 0.0935, -0.0260, -0.2900, -0.1393,  0.3366, -0.0941, -0.1650,  0.0064],\n",
      "        [-0.0167, -0.0357, -0.0669, -0.1720, -0.3252, -0.1597,  0.3037, -0.2102],\n",
      "        [ 0.2953,  0.2926, -0.1229, -0.0789,  0.1321,  0.1968,  0.1933,  0.1643],\n",
      "        [-0.0559,  0.2061,  0.2895,  0.0070, -0.3295,  0.0508, -0.0993, -0.2488],\n",
      "        [-0.3074,  0.1435,  0.0608, -0.3500,  0.2708, -0.0079,  0.0961,  0.0702],\n",
      "        [ 0.2418, -0.0709,  0.1332, -0.1438,  0.1101,  0.3273, -0.1488, -0.2666],\n",
      "        [ 0.1220,  0.3451, -0.0257,  0.0022, -0.2604, -0.1920, -0.1468, -0.2362]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0151,  0.1497,  0.1205, -0.1843,  0.0263, -0.1881, -0.0805,  0.1663,\n",
      "        -0.2293], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0726, -0.3145,  0.0356,  0.1332, -0.2046, -0.1172,  0.2581,  0.3070,\n",
      "         -0.1992]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2810], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "costf = torch.nn.MSELoss(reduction='sum') # Puedo usar la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.147644271850586\n",
      "100 0.12824777603149415\n",
      "200 0.011302996873855591\n",
      "300 0.00471315860748291\n",
      "400 0.002787270247936249\n",
      "500 0.0019158144295215607\n",
      "600 0.00143657386302948\n",
      "700 0.0011397494375705718\n",
      "800 0.000940251350402832\n",
      "900 0.0007979732751846314\n",
      "1000 0.0006918620318174362\n",
      "1100 0.000609929971396923\n",
      "1200 0.000544891357421875\n",
      "1300 0.0004920860007405281\n",
      "1400 0.000448407344520092\n",
      "1500 0.00041170634329319\n",
      "1600 0.00038045436143875123\n",
      "1700 0.0003535342589020729\n",
      "1800 0.0003301125392317772\n",
      "1900 0.0003095550835132599\n",
      "2000 0.0002913709543645382\n",
      "2100 0.00027517473325133323\n",
      "2200 0.0002606595680117607\n",
      "2300 0.00024757830426096916\n",
      "2400 0.00023573001846671104\n",
      "2500 0.00022494930773973466\n",
      "2600 0.00021509820595383644\n",
      "2700 0.0002060626447200775\n",
      "2800 0.00019774556159973144\n",
      "2900 0.00019006505608558654\n",
      "3000 0.0001829507015645504\n",
      "3100 0.00017634274438023566\n",
      "3200 0.0001701890118420124\n",
      "3300 0.00016444452106952666\n",
      "3400 0.00015906946733593941\n",
      "3500 0.00015403006225824355\n",
      "3600 0.00014929525554180145\n",
      "3700 0.00014483888633549214\n",
      "3800 0.0001406368613243103\n",
      "3900 0.00013666814193129538\n",
      "4000 0.00013291398994624614\n",
      "4100 0.00012935734353959562\n",
      "4200 0.00012598324567079545\n",
      "4300 0.00012277789413928986\n",
      "4400 0.00011972894892096519\n",
      "4500 0.00011682536453008652\n",
      "4600 0.00011405698955059051\n",
      "4700 0.00011141474358737469\n",
      "4800 0.00010888994671404362\n",
      "4900 0.00010647515766322613\n",
      "5000 0.00010416349396109581\n",
      "5100 0.00010194821283221245\n",
      "5200 9.982376359403133e-05\n",
      "5300 9.778445586562156e-05\n",
      "5400 9.582522325217724e-05\n",
      "5500 9.394164197146893e-05\n",
      "5600 9.212961420416832e-05\n",
      "5700 9.038475342094898e-05\n",
      "5800 8.870363235473633e-05\n",
      "5900 8.708279579877854e-05\n",
      "6000 8.551931008696556e-05\n",
      "6100 8.400953374803067e-05\n",
      "6200 8.255155757069587e-05\n",
      "6300 8.114214055240155e-05\n",
      "6400 7.977962493896484e-05\n",
      "6500 7.846088148653507e-05\n",
      "6600 7.718457374721765e-05\n",
      "6700 7.594844792038202e-05\n",
      "6800 7.475026417523623e-05\n",
      "6900 7.35887698829174e-05\n",
      "7000 7.246242836117745e-05\n",
      "7100 7.136953994631768e-05\n",
      "7200 7.030818145722151e-05\n",
      "7300 6.927746348083019e-05\n",
      "7400 6.827606819570064e-05\n",
      "7500 6.73027290031314e-05\n",
      "7600 6.635626312345266e-05\n",
      "7700 6.543565075844526e-05\n",
      "7800 6.45399745553732e-05\n",
      "7900 6.366785150021315e-05\n",
      "8000 6.281875539571047e-05\n",
      "8100 6.199157796800136e-05\n",
      "8200 6.118559278547764e-05\n",
      "8300 6.0399975627660754e-05\n",
      "8400 5.963397677987814e-05\n",
      "8500 5.8886557817459106e-05\n",
      "8600 5.815772339701652e-05\n",
      "8700 5.744669120758772e-05\n",
      "8800 5.675213411450386e-05\n",
      "8900 5.607367493212223e-05\n",
      "9000 5.54116303101182e-05\n",
      "9100 5.476458463817835e-05\n",
      "9200 5.413202568888664e-05\n",
      "9300 5.351384170353413e-05\n",
      "9400 5.2909660153090956e-05\n",
      "9500 5.231834482401609e-05\n",
      "9600 5.174034740775824e-05\n",
      "9700 5.117448978126049e-05\n",
      "9800 5.062074400484562e-05\n",
      "9900 5.007899831980467e-05\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "for t in range(9999):\n",
    "    y = model(x) # Puedo usarlo como funcion\n",
    "    model.zero_grad() # Reseteo los gradientes antes del backprop\n",
    "    error = costf(y, z)\n",
    "    error.backward()\n",
    "    with torch.no_grad(): # Lo que haga aca adentro no actualiza el gradiente\n",
    "        for param in model.parameters():\n",
    "            param -= lr * param.grad # Pero esto actualiza w1 y w2 pero tambien h e y?\n",
    "    if not t % 100:\n",
    "        print(t, error.item() / P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
